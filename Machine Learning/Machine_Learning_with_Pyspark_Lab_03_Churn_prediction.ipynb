{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SG1CWw6ppO9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1bc184-6318-4cea-f63e-816d3cb41506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import packages"
      ],
      "metadata": {
        "id": "tuix5kwr3SnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---for google colab / jupyter notebook\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "#----------------------------------------\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "mf6bKQHsMpEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Session"
      ],
      "metadata": {
        "id": "pDeTBNC13Vxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark = SparkSession.builder.appName(\"Churn Prediction with PySpark\").getOrCreate()"
      ],
      "metadata": {
        "id": "P9oGBqMMz2vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download Dataset"
      ],
      "metadata": {
        "id": "wHMBkJTw3Y9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/urfie/belajar-python/raw/master/Machine%20Learning/churn60.csv.gz"
      ],
      "metadata": {
        "id": "fTHMVZCT4Aui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load to Spark DataFrame"
      ],
      "metadata": {
        "id": "exScOPDh3b7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn = spark.read.csv('churn60.csv.gz', header='true', inferSchema='true')"
      ],
      "metadata": {
        "id": "jDA9hIkr2lfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quick Check"
      ],
      "metadata": {
        "id": "Ck8Oj3Yh3fd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.show(10)"
      ],
      "metadata": {
        "id": "QSe8Glff7YxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Describe"
      ],
      "metadata": {
        "id": "OGKsXDle3iN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.describe().show()"
      ],
      "metadata": {
        "id": "Gv-EUpXT9dTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Print Schema"
      ],
      "metadata": {
        "id": "foBEB0PR3jqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.printSchema()"
      ],
      "metadata": {
        "id": "zFNEWH3U-GB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check Categorical Data"
      ],
      "metadata": {
        "id": "nazkx68a3lgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.select('account_status').distinct().show()"
      ],
      "metadata": {
        "id": "53u2YyvUDm56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.select('subscriber_status').distinct().show()"
      ],
      "metadata": {
        "id": "Ae8jEpp1Dy4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.select('occupation').distinct().show()"
      ],
      "metadata": {
        "id": "ig0ZzQkwEAgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.select('education').distinct().show()"
      ],
      "metadata": {
        "id": "s53S1iiaECdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.select('marital_status').distinct().show()"
      ],
      "metadata": {
        "id": "JFhksd8oEFS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.select('sex').distinct().show()"
      ],
      "metadata": {
        "id": "PmFUnd7NV4NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn = df_churn.withColumn('sex', F.when(df_churn.sex=='MALE', 'MAL').otherwise(df_churn.sex))\n",
        "df_churn.select('sex').distinct().show()"
      ],
      "metadata": {
        "id": "azhR7tNyV741"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Select features"
      ],
      "metadata": {
        "id": "bZlQpux538su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = ['lifetime','age','voice_out_onnet_freq','voice_out_onnet_dur','voice_out_onnet_chg',\n",
        "            'voice_out_mobile_freq','voice_out_mobile_dur','voice_out_mobile_chg','voice_out_pstn_freq',\n",
        "            'voice_out_pstn_dur','voice_out_pstn_chg','voice_out_spcnum_freq','voice_out_spcnum_dur',\n",
        "            'voice_out_spcnum_chg','voice_out_sli_freq','voice_out_sli_dur','voice_out_sli_chg',\n",
        "            'voice_in_onnet_freq','voice_in_onnet_dur','sms_out_onnet_freq','sms_out_onnet_chg','sms_out_offnet_freq',\n",
        "            'sms_out_offnet_chg','sms_in_onnet_freq','mms_out_onnet_freq',\n",
        "            'mms_out_onnet_chg','data_freq','data_vol','data_ch','total_revenue']"
      ],
      "metadata": {
        "id": "jHHeuNJDD_hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = ['account_status','subscriber_status','sex','occupation','education','marital_status']"
      ],
      "metadata": {
        "id": "PqPs9RvfJ88z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Null handling"
      ],
      "metadata": {
        "id": "2jFosDMM4DKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn = df_churn.fillna(0, subset=num_cols)"
      ],
      "metadata": {
        "id": "0M0UOS1MY_xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plot churn distribution"
      ],
      "metadata": {
        "id": "R5N6EwyD3qN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfplot = df_churn.groupBy('churn').count().toPandas()\n",
        "plt.bar(dfplot['churn'], dfplot['count'])"
      ],
      "metadata": {
        "id": "dtFZbwT3Ozfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Correlation"
      ],
      "metadata": {
        "id": "G4gkBOdw4HVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "#convert each DataFrame column to vectors\n",
        "vector_col = 'corr_features'\n",
        "assembler = VectorAssembler(inputCols=num_cols, outputCol=vector_col)\n",
        "df_vector = assembler.transform(df_churn).select(vector_col)"
      ],
      "metadata": {
        "id": "sFfRQI5PdHxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate correlation matrix\n",
        "matrix = Correlation.corr(df_vector, vector_col)\n",
        "corrmatrix = matrix.collect()[0][0].toArray().tolist()"
      ],
      "metadata": {
        "id": "VIuUhbEsfLxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfp = pd.DataFrame(corrmatrix, columns=num_cols, index=num_cols)\n",
        "ax = sns.heatmap(dfp)"
      ],
      "metadata": {
        "id": "Hqp7IW3VftXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encode"
      ],
      "metadata": {
        "id": "M85LUyDBk6rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dummy(df,indexCol,categoricalCols,continuousCols,labelCol):\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    from pyspark.sql.functions import col\n",
        "\n",
        "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
        "                 for c in categoricalCols ]\n",
        "\n",
        "    # default setting: dropLast=True\n",
        "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
        "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
        "                 for indexer in indexers ]\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
        "                                + continuousCols, outputCol=\"features\")\n",
        "\n",
        "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "\n",
        "    model=pipeline.fit(df)\n",
        "    data = model.transform(df)\n",
        "\n",
        "    data = data.withColumn('label', col(labelCol))\n",
        "\n",
        "    return data.select(indexCol,'features','label')"
      ],
      "metadata": {
        "id": "dlZFjfa1P9Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = get_dummy(df_churn, 'msisdn', cat_cols, num_cols, 'churn')"
      ],
      "metadata": {
        "id": "T20RsLLLMHJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "4E0FJauUTljm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.count()"
      ],
      "metadata": {
        "id": "jFfqqlqiXrrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split Data"
      ],
      "metadata": {
        "id": "ffn_BJdr4d-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df_encoded.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "IWVxB-YPUoed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create and train Model"
      ],
      "metadata": {
        "id": "iEZywikr4f5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "dTree = DecisionTreeClassifier(labelCol='label', featuresCol='features')"
      ],
      "metadata": {
        "id": "a6dg1dftU9_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dTree_model = dTree.fit(trainingData)"
      ],
      "metadata": {
        "id": "ntl__N9BVDHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Make Prediction"
      ],
      "metadata": {
        "id": "4dt-oOt94kL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions.\n",
        "predictions = dTree_model.transform(testData)\n",
        "# Select example rows to display.\n",
        "predictions.show(5)"
      ],
      "metadata": {
        "id": "wEngfn9VVHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate"
      ],
      "metadata": {
        "id": "emqSXiKz4z8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "YZmo8VjEZrAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
        "churn_acc  = churn_eval.evaluate(predictions, {churn_eval.metricName:\"accuracy\"})\n",
        "print(\"Decision Tree Performance Measure\")\n",
        "print(\"Accuracy = %0.2f\" % churn_acc)"
      ],
      "metadata": {
        "id": "8XAxUzmFaLs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_eval = BinaryClassificationEvaluator(rawPredictionCol=\"probability\", labelCol=\"label\")\n",
        "churn_auc  = churn_eval.evaluate(predictions)\n",
        "print(\"AUC = %.2f\" % churn_auc)"
      ],
      "metadata": {
        "id": "AwIEgtBfaoFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "cm_result = predictions.crosstab(\"prediction\", \"label\")\n",
        "cm_result = cm_result.toPandas()\n",
        "cm_result.sort_values(by = ['prediction_label'])"
      ],
      "metadata": {
        "id": "Umgl-EZ-bK3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP = cm_result[\"1\"][0]\n",
        "FP = cm_result[\"0\"][0]\n",
        "TN = cm_result[\"0\"][1]\n",
        "FN = cm_result[\"1\"][1]\n",
        "Accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
        "Sensitivity = TP/(TP+FN)\n",
        "Specificity = TN/(TN+FP)\n",
        "Precision = TP/(TP+FP)\n",
        "\n",
        "print (\"Accuracy = %0.2f\" %Accuracy )\n",
        "print (\"Sensitivity = %0.2f\" %Sensitivity )\n",
        "print (\"Specificity = %0.2f\" %Specificity )\n",
        "print (\"Precision = %0.2f\" %Precision )"
      ],
      "metadata": {
        "id": "tuQyRlQOcBpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}